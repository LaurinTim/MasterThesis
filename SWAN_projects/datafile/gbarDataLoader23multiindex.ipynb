{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0d431536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/eos/home-i00/l/lkoller/data-analysis-software')\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fnmatch, re\n",
    "import pytimber\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from time import mktime\n",
    "from tqdm import tqdm\n",
    "import lmfit\n",
    "from readTrc_4CH import Trc\n",
    "import gbarDataLoader as gd\n",
    "\n",
    "#replace these three paths\n",
    "############################################################################################\n",
    "DATASUMMARY = Path('/eos') / 'user' / 'l' / 'lkoller' / 'GBAR' / 'data23' / 'datasummary23'\n",
    "ELENASAVE = Path('/eos') / 'user' / 'l' / 'lkoller' / 'GBAR' / 'data23' / 'elenadata23'\n",
    "DATAFILE = Path('/eos') / 'user' / 'l' / 'lkoller' / 'GBAR' / 'data23'\n",
    "############################################################################################\n",
    "\n",
    "PROTONGUNPC = Path('/eos') / 'experiment' / 'gbar' /'pgunpc' / 'data'\n",
    "RCPC = Path('/eos') / 'experiment' / 'gbar' / 'rcpc' / 'data'\n",
    "ELENADATA = Path('/eos') / 'experiment' / 'gbar' / 'elena' / 'data'\n",
    "\n",
    "#list with the names of the columns for the files in the pgungc/data/date/date.txt (replace date)\n",
    "sequence_logFile = ['Time','valv_pos','mcp_pos','i_beam','wf','amp_FC','amp_RC','amp_SWY','sum_pco','I_focus','uhf_read','is_pressure','u_beam',\n",
    " 'u_focus','input1','input2','u_beam_set','u_focus_set','uhf_set','gas_inlet_set','EL_pT_in','EL_pT_1','EL_pT_2','EL_pT_3','EL_pT_4','EL_pT_out',\n",
    " 'EL_TL1','EL_TL2','ST_dec_up','ST_dec_dw','ST_dec_ri','ST_dec_le','St_TL_up','St_TL_dw','St_TL_ri','St_TL_le','EL_pbL1','EL_pbL2','EL_pbl3','St_pbl_up',\n",
    " 'St_pbl_dw','St_pbl_le','St_pbl_ri','pbT_in_+','pbT_out_+','Ly_MCP_1','Ly_MCP_2','Ly_MCP_3','Ly_MCP_4','Sci_1','Sci_2','EL_RC1','St_RC1_up',\n",
    " 'St_RC1_dw','St_RC1_le','St_RC1_ri','St_RC2_up','St_RC2_dw','St_RC2_le','St_RC2_ri','St_RC3_up','St_RC3_dw','St_RC3_le','St_RC3_ri','QT_RC1_+','QT_RC1_-',\n",
    " 'QT_RC2_+','QT_RC2_-','QT_RC3_+','QT_RC3_-','SwY_1_+','SwY_2_-','SwY_3_+','SwY_4_-','SWY_EL','6_PbT_pho_+','6_PbT_mcp_+','4_RC_pho_+','4_RC_mcp_+',\n",
    " '5_SwY_pho_+','5_SwY_mcp_+','Defl_+','Qnch_+','Qnch_-','pr_h','pr_qb','pr_rc','pr_mw','pr_swy','pr_lya','H_offset','target','delay_A','delay_B',\n",
    " 'delay_C','delay_E','delay_G','MCP_front_bias']\n",
    "\n",
    "#list with the names of the columns for the rcpc and pgunpc\n",
    "sequence = ['MCP1', 'MCP2', 'MCP3', 'MCP4', 'MCP5', 'MCP7', 'Waveform_12bit', 'CMOS_Tracker', 'DRS4',\n",
    "                'Positron_CH1','Positron_CH2','Positron_CH3','Positron_CH4','SD','LyA','SD_LyA']\n",
    "\n",
    "#list with the names of the columns for the data from elena\n",
    "elena_sequence = ['Cy_Des','NE00_I','NE50_I', 'NE00_Bm1', 'NE00_Bm2', 'NE00_Bm3', 'NE50_Bm1', 'NE50_Bm2', 'Int']\n",
    "    \n",
    "\n",
    "def loadVIS():\n",
    "    '''\n",
    "    \n",
    "    Set some general rules how dataframes and plots are displayed\n",
    "    \n",
    "    '''\n",
    "    pd.set_option(\"display.max_columns\",None)\n",
    "    plt.rcParams['axes.facecolor'] = 'white'\n",
    "    plt.rcParams['axes.spines.left'] = True #False\n",
    "    plt.rcParams['axes.spines.right'] = True #False\n",
    "    plt.rcParams['axes.spines.top'] = True #False\n",
    "    plt.rcParams['axes.spines.bottom'] = True #False\n",
    "    plt.rcParams['axes.grid'] = False\n",
    "    plt.rcParams['axes.grid.axis'] = 'both'\n",
    "    plt.rcParams['axes.labelcolor'] = '#555555'\n",
    "    plt.rcParams['text.color'] = 'black'\n",
    "    plt.rcParams['figure.figsize'] = 6,4\n",
    "    plt.rcParams['figure.dpi'] = 600\n",
    "    plt.rcParams['figure.titleweight'] = 'normal'\n",
    "    plt.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "def loadLog(date2an):\n",
    "    '''\n",
    "\n",
    "    Load Christians DAQ file from the protongun PC and label the columns\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    date2an = the date for which we want to create a log file\n",
    "    \n",
    "    '''\n",
    "    if ((DATASUMMARY / date2an / ('log_'+date2an+'.txt')).is_file() == True) and (date2an < datetime.fromtimestamp((DATASUMMARY / date2an / ('log_'+date2an+'.txt')).stat().st_mtime).strftime('%y_%m_%d')):\n",
    "        print('LOG file for '+date2an+' already exists.')\n",
    "        return pd.read_csv(str(DATASUMMARY / date2an / ('log_'+date2an+'.txt')), sep='\\t')\n",
    "    else:\n",
    "        if not (PROTONGUNPC / date2an).exists() or not (PROTONGUNPC / date2an / (date2an+'.txt')).is_file():\n",
    "            print('Wrong date formate or date is not uploaded yet.')     \n",
    "        else:\n",
    "            if not (DATASUMMARY/ date2an).exists():\n",
    "                Path.mkdir(DATASUMMARY / date2an) \n",
    "            logfile = PROTONGUNPC / date2an / (date2an+'.txt')\n",
    "            \n",
    "            log = pd.read_csv(logfile, sep='\\t', header=None)\n",
    "            \n",
    "            for i in range(len(sequence_logFile)):\n",
    "                log = log.rename(columns={i: sequence_logFile[i]})\n",
    "            \n",
    "            log.to_csv(str(DATASUMMARY / date2an / ('log_'+date2an+'.txt')), sep='\\t', index=False)\n",
    "            return log\n",
    "        \n",
    "\n",
    "\n",
    "def loadRCPC(date2an):\n",
    "    '''\n",
    "    \n",
    "    Get the times and locations for the files from the different MCPs which are in the RCPC folder\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    date2an = the date for which we want to create a log file\n",
    "    \n",
    "    Returns\n",
    "    ------------\n",
    "    dataframe with the times and filenames for the MCPSs at date2an sorted by time\n",
    "    \n",
    "    '''\n",
    "    mcp1_file = []\n",
    "    mcp1_time = []\n",
    "    mcp2_file = []\n",
    "    mcp2_time = []\n",
    "    mcp3_file = []\n",
    "    mcp3_time = []\n",
    "    mcp4_file = []\n",
    "    mcp4_time = []\n",
    "    mcp7_file = []\n",
    "    mcp7_time = []\n",
    "    \n",
    "    if (RCPC / date2an).exists() == False:\n",
    "        print('RCPC files might not have been uploaded yet.')\n",
    "    else:\n",
    "        p = RCPC / date2an\n",
    "        for file in p.iterdir():\n",
    "            if fnmatch.fnmatch(file, '*MCP1*') and fnmatch.fnmatch(file, '*.tif') and fnmatch.fnmatch(file, '*.sys.v#.*') == False:\n",
    "                mcp1_time.append(int(re.search('G16\\_(.*?)\\.', str(file)).group(1)))\n",
    "                mcp1_file.append(file)\n",
    "            if fnmatch.fnmatch(file, '*MCP2*') and fnmatch.fnmatch(file, '*.tif') and fnmatch.fnmatch(file, '*.sys.v#.*') == False:\n",
    "                mcp2_time.append(int(re.search('G16\\_(.*?)\\.', str(file)).group(1)))\n",
    "                mcp2_file.append(file)\n",
    "            if fnmatch.fnmatch(file, '*MCP3*') and fnmatch.fnmatch(file, '*.tif') and fnmatch.fnmatch(file, '*.sys.v#.*') == False:\n",
    "                mcp3_time.append(int(re.search('G16\\_(.*?)\\.', str(file)).group(1)))\n",
    "                mcp3_file.append(file)\n",
    "            if (fnmatch.fnmatch(file, '*PCO-ReC*') or fnmatch.fnmatch(file, '*MCP5*')) and fnmatch.fnmatch(file, '*.sys.v#.*') == False:\n",
    "                mcp4_time.append(int(re.search('s\\_(.*?)\\.', str(file)).group(1)))\n",
    "                mcp4_file.append(file)\n",
    "            if (fnmatch.fnmatch(file, '*VCXG-51M-7*') and fnmatch.fnmatch(file, '*.tif')) and fnmatch.fnmatch(file, '*.sys.v#.*') == False:\n",
    "                mcp7_time.append(int(re.search('G16\\_(.*?)\\.', str(file)).group(1)))\n",
    "                mcp7_file.append(file)\n",
    "        \n",
    "    df1 = pd.DataFrame({'Time' : mcp1_time, 'MCP1' : mcp1_file})\n",
    "    df2 = pd.DataFrame({'Time' : mcp2_time, 'MCP2' : mcp2_file})\n",
    "    df3 = pd.DataFrame({'Time' : mcp3_time, 'MCP3' : mcp3_file})\n",
    "    df4 = pd.DataFrame({'Time' : mcp4_time, 'MCP4' : mcp4_file})\n",
    "    df7 = pd.DataFrame({'Time' : mcp7_time, 'MCP7' : mcp7_file})  \n",
    "    return pd.concat([df1,df2,df3,df4,df7], ignore_index=True).sort_values('Time', ascending=True, ignore_index=True)\n",
    "        \n",
    "\n",
    "def loadPGUNPC(date2an):\n",
    "    '''\n",
    "    \n",
    "    files from the PGUNPC from date2an into a dataframe\n",
    "    \n",
    "    df5 are the locations of the pictures taken by MCP5\n",
    "    dfwf are the locations of the waveform files\n",
    "    dfcmos are the locations cmos detector\n",
    "    dfdrs is deinstalled now\n",
    "    dfposi1 are the locations positron waveform 1\n",
    "    dfposi2 are the locations positron waveform 2\n",
    "    dfposi3 are the locations positron waveform 3\n",
    "    dfposi4 are the locations positron waveform 4\n",
    "    dfsdposi are the locations png of the oscilloscope for the positrons\n",
    "    dflya are the locations of the trc files with the data of the 4 channels from the lyman alpha setup\n",
    "    dfsdlya are the locations png of the oscilloscope for the lya\n",
    "    \n",
    "    Returns\n",
    "    ------------\n",
    "    dataframe with all the data from above sorted by time. The columns are:\n",
    "        df5 are the locations of the pictures taken by MCP5\n",
    "        dfwf are the locations of the waveform files\n",
    "        dfcmos are the locations cmos detector\n",
    "        dfdrs is deinstalled now\n",
    "        dfposi1 are the locations positron waveform 1\n",
    "        dfposi2 are the locations positron waveform 2\n",
    "        dfposi3 are the locations positron waveform 3\n",
    "        dfposi4 are the locations positron waveform 4\n",
    "        dfsdposi are the locations png of the oscilloscope for the positrons\n",
    "        dflya are the locations of the trc files with the data of the 4 channels from the lyman alpha setup\n",
    "        dfsdlya are the locations png of the oscilloscope for the lya    \n",
    "    \n",
    "    '''\n",
    "    mcp5_time, mcp5_file = [],[]\n",
    "    waveform_time, waveform_file = [],[]\n",
    "    cmos_time, cmos_file = [],[]\n",
    "    drs_time, drs_file = [],[]\n",
    "    posi_c1_time, posi_c1_file = [],[]\n",
    "    posi_c2_time, posi_c2_file = [],[]\n",
    "    posi_c3_time, posi_c3_file = [],[]\n",
    "    posi_c4_time, posi_c4_file = [],[]\n",
    "    sd_posi_time, sd_posi_file = [],[]\n",
    "    lya_time, lya_file = [],[]\n",
    "    sd_lya_time, sd_lya_file = [],[]\n",
    "    \n",
    "    if (PROTONGUNPC / date2an).exists() == False:\n",
    "        print('PGunPC files might not have been uploaded yet.')\n",
    "    else:\n",
    "        p = PROTONGUNPC / date2an\n",
    "        posi = p / (date2an+'posi')\n",
    "        lya = p / (date2an+'lya')\n",
    "        for file in p.iterdir():\n",
    "            if (fnmatch.fnmatch(file, '*PCO-SwY*') or fnmatch.fnmatch(file, '*MCP6*')) and fnmatch.fnmatch(file, '*.sys.v#.*') == False:\n",
    "                mcp5_time.append(int(re.search('s\\_(.*?)\\.', str(file)).group(1)))\n",
    "                mcp5_file.append(file)\n",
    "            if fnmatch.fnmatch(file, '*WF1234*') and fnmatch.fnmatch(file,'*.trc') and fnmatch.fnmatch(file, '*.sys.v#.*') == False:\n",
    "                waveform_time.append(int(re.search('WF1234\\.(.*?)\\.', str(file)).group(1)))\n",
    "                waveform_file.append(file)\n",
    "            if fnmatch.fnmatch(file, '*VCXG-51M-5*') and fnmatch.fnmatch(file, '*.tif') and fnmatch.fnmatch(file, '*.sys.v#.*') == False:\n",
    "                cmos_time.append(int(re.search('G16\\_(.*?)\\.', str(file)).group(1)))\n",
    "                cmos_file.append(file)\n",
    "            if fnmatch.fnmatch(file, '*drs4*') and fnmatch.fnmatch(file, '*.txt') and fnmatch.fnmatch(file, '*.sys.v#.*') == False:\n",
    "                filetime = re.search('drs4\\_(.*?)\\.', str(file)).group(1)\n",
    "                drs_time.append(int(mktime(datetime(int('20'+filetime[0:2]),int(filetime[3:5]),int(filetime[6:8]),int(filetime[9:11]), int(filetime[12:14]), int(filetime[15:17])).timetuple())))\n",
    "                drs_file.append(file)\n",
    "        if (posi.exists()):\n",
    "            for file in posi.iterdir():\n",
    "                if fnmatch.fnmatch(file, '*C1*') and fnmatch.fnmatch(file, '*.trc') and fnmatch.fnmatch(file, '*.sys.v#.*') == False:\n",
    "                    posi_c1_time.append(int(re.search('C1\\.(.*?)\\.', str(file)).group(1)))\n",
    "                    posi_c1_file.append(file)\n",
    "                if fnmatch.fnmatch(file, '*C2*') and fnmatch.fnmatch(file, '*.trc') and fnmatch.fnmatch(file, '*.sys.v#.*') == False:\n",
    "                    posi_c2_time.append(int(re.search('C2\\.(.*?)\\.', str(file)).group(1)))\n",
    "                    posi_c2_file.append(file) \n",
    "                if fnmatch.fnmatch(file, '*C3*') and fnmatch.fnmatch(file, '*.trc') and fnmatch.fnmatch(file, '*.sys.v#.*') == False:\n",
    "                    posi_c3_time.append(int(re.search('C3\\.(.*?)\\.', str(file)).group(1)))\n",
    "                    posi_c3_file.append(file)\n",
    "                if fnmatch.fnmatch(file, '*C4*') and fnmatch.fnmatch(file, '*.trc') and fnmatch.fnmatch(file, '*.sys.v#.*') == False:\n",
    "                    posi_c4_time.append(int(re.search('C4\\.(.*?)\\.', str(file)).group(1)))\n",
    "                    posi_c4_file.append(file)\n",
    "                if fnmatch.fnmatch(file, '*SD*') and fnmatch.fnmatch(file, '*.png') and fnmatch.fnmatch(file, '*.sys.v#.*') == False:\n",
    "                    sd_posi_time.append(int(re.search('SD\\.(.*?)\\.', str(file)).group(1)))\n",
    "                    sd_posi_file.append(file)\n",
    "        if (lya.exists()):\n",
    "            for file in lya.iterdir():\n",
    "                if fnmatch.fnmatch(file, '*LY*') and fnmatch.fnmatch(file, '*.trc') and fnmatch.fnmatch(file, '*.sys.v#.*') == False:\n",
    "                    lya_time.append(int(re.search('LY1234\\.(.*?)\\.', str(file)).group(1)))\n",
    "                    lya_file.append(file)\n",
    "                \"\"\"\n",
    "                if fnmatch.fnmatch(file, '*C2*') and fnmatch.fnmatch(file, '*.trc'):\n",
    "                    lya_c2_time.append(int(re.search('C2\\.(.*?)\\.', str(file)).group(1)))\n",
    "                    lya_c2_file.append(file) \n",
    "                if fnmatch.fnmatch(file, '*C3*') and fnmatch.fnmatch(file, '*.trc'):\n",
    "                    lya_c3_time.append(int(re.search('C3\\.(.*?)\\.', str(file)).group(1)))\n",
    "                    lya_c3_file.append(file)\n",
    "                if fnmatch.fnmatch(file, '*C4*') and fnmatch.fnmatch(file, '*.trc'):\n",
    "                    lya_c4_time.append(int(re.search('C4\\.(.*?)\\.', str(file)).group(1)))\n",
    "                    lya_c4_file.append(file)\n",
    "                \"\"\"\n",
    "                if fnmatch.fnmatch(file, '*SD*') and fnmatch.fnmatch(file, '*.png') and fnmatch.fnmatch(file, '*.sys.v#.*') == False:\n",
    "                    sd_lya_time.append(int(re.search('SD\\.(.*?)\\.', str(file)).group(1)))\n",
    "                    sd_lya_file.append(file)\n",
    "    df5 = pd.DataFrame({'Time' : mcp5_time, 'MCP5' : mcp5_file})\n",
    "    dfwf = pd.DataFrame({'Time' : waveform_time, 'Waveform_12bit' : waveform_file})\n",
    "    dfcmos = pd.DataFrame({'Time' : cmos_time, 'CMOS_Tracker' : cmos_file})\n",
    "    dfdrs = pd.DataFrame({'Time' : drs_time, 'DRS4'  : drs_file})\n",
    "    dfposi1 = pd.DataFrame({'Time' : posi_c1_time, 'Positron_CH1' : posi_c1_file})\n",
    "    dfposi2 = pd.DataFrame({'Time' : posi_c2_time, 'Positron_CH2' : posi_c2_file})\n",
    "    dfposi3 = pd.DataFrame({'Time' : posi_c3_time, 'Positron_CH3' : posi_c3_file})\n",
    "    dfposi4 = pd.DataFrame({'Time' : posi_c4_time, 'Positron_CH4' : posi_c4_file})\n",
    "    dfsdposi = pd.DataFrame({'Time' : sd_posi_time, 'SD':sd_posi_file})\n",
    "    dflya = pd.DataFrame({'Time' : lya_time, 'LyA' : lya_file})\n",
    "    #dflya2 = pd.DataFrame({'Time' : lya_c2_time, 'LyA_CH2' : lya_c2_file})\n",
    "    #dflya3 = pd.DataFrame({'Time' : lya_c3_time, 'LyA_CH3' : lya_c3_file})\n",
    "    #dflya4 = pd.DataFrame({'Time' : lya_c4_time, 'LyA_CH4' : lya_c4_file})\n",
    "    dfsdlya = pd.DataFrame({'Time' : sd_lya_time, 'SD_LyA':sd_lya_file})\n",
    "    return pd.concat([df5, dfwf, dfcmos, dfdrs, dfposi1, dfposi2, dfposi3, dfposi4, dfsdposi, dflya, dfsdlya], ignore_index=True).sort_values('Time', ascending=True, ignore_index=True)\n",
    "\n",
    "def loadElena(date2an):\n",
    "    '''\n",
    "    Get the parameters for the Elena/AD runs on the day date2an and return them in a dataframe\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    date2an = the date from which we want the data\n",
    "    \n",
    "    Returns\n",
    "    ------------\n",
    "    elena = dataframe with the data for the elena runs on date2an, the colums are:\n",
    "        Time = unix timestamp of the cycle\n",
    "        Cy_Des = description of the cycle parameters\n",
    "        NE00_I = NE00 Intensity\n",
    "        NE50_I = NE50 Intensity\n",
    "        NE00_Bm1 = Whether or not the first beam monitor for the NE00 line is in\n",
    "        NE00_Bm2 = Whether or not the second beam monitor for the NE00 line is in\n",
    "        NE00_Bm3 = Whether or not the third beam monitor for the NE00 line is in\n",
    "        NE50_Bm1 = Whether or not the first beam monitor for the NE50 line is in\n",
    "        NE50_Bm2 = Whether or not the second beam monitor for the NE50 line is in\n",
    "        Int = Total intensity\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    if ((ELENASAVE / ('elena_' + date2an + '.txt')).is_file() == True):\n",
    "        print('Elena file for ' + date2an + ' already exists.')\n",
    "        return pd.read_csv(str(ELENASAVE / ('elena_'+date2an+'.txt')), sep='\\t')\n",
    "    \n",
    "    bm = pd.read_csv(ELENADATA / date2an / ('ELENA_BM_' + date2an + '.csv'), header = 0, \n",
    "                     names = ['Time','NE00_I','NE50_I', 'NE00_Bm1', 'NE00_Bm2', 'NE00_Bm3', 'NE50_Bm1', 'NE50_Bm2', 'Int'])\n",
    "    cy = pd.read_csv(ELENADATA / date2an / ('ELENA_Cycles_' + date2an + '.csv'), header = 0, names = ['Time', 'Cy_Des'])\n",
    "    \n",
    "    if (bm.shape[0] != cy.shape[0]):\n",
    "        return print('cycle and beam data does not match')\n",
    "    \n",
    "    bm = bm.drop(['Time'], axis = 1)\n",
    "    \n",
    "    elena = pd.concat([cy,bm], axis = 1).round({'Time':0}).sort_values(by = ['Time'])\n",
    "    \n",
    "    elena['Time'] = elena['Time'] + 12\n",
    "    \n",
    "    elena.to_csv(str(ELENASAVE / ('elena_'+date2an+'.txt')), sep='\\t', index=False)\n",
    "    \n",
    "    return elena\n",
    "\n",
    "def loadDatafile(date2an):\n",
    "    '''\n",
    "    \n",
    "    match all the data from elena, pgunpc and rcpc to the correct event in the log file\n",
    "    \n",
    "    '''\n",
    "    if ((DATASUMMARY / date2an / ('summary_'+date2an+'.txt')).is_file() == True) and (date2an < datetime.fromtimestamp((DATASUMMARY / date2an / ('summary_'+date2an+'.txt')).stat().st_mtime).strftime('%y_%m_%d') ):\n",
    "        print('SUMMARY file for '+date2an+' already exists.')\n",
    "        return pd.read_csv(str(DATASUMMARY / date2an / ('summary_'+date2an+'.txt')), sep='\\t')\n",
    "    else:\n",
    "        if not (DATASUMMARY/ date2an).exists():\n",
    "            Path.mkdir(DATASUMMARY / date2an) \n",
    "        dfpgun = loadPGUNPC(date2an)\n",
    "        dfrcpc = loadRCPC(date2an)\n",
    "        dflog = loadLog(date2an)\n",
    "\n",
    "        datafiles= pd.concat([dfpgun, dfrcpc], ignore_index=True).round({'Time':0}).sort_values(['Time'])\n",
    "        \n",
    "        elena = loadElena(date2an)\n",
    "        \n",
    "        cont = True #track for datafiles if we can continue (for some reason break does not work?)\n",
    "        pos = 0\n",
    "        epos = 0\n",
    "        for idx, timestamp in tqdm(enumerate(dflog['Time']), total = len(dflog)):\n",
    "            \n",
    "            for eidy, ets in enumerate(elena['Time'][epos:]):\n",
    "                if (abs(timestamp - ets) < 7):\n",
    "                    epos = eidy + epos\n",
    "                    for elabel in elena_sequence:\n",
    "                        dflog.loc[idx, elabel] = elena[elabel][epos]\n",
    "                    break\n",
    "                    \n",
    "            if not (timestamp - datafiles['Time'][0]) < -7:\n",
    "                for idy, ts in enumerate(datafiles['Time'][pos:]):\n",
    "                    if abs(timestamp - ts) < 7:\n",
    "                        pos = idy + pos\n",
    "                        break\n",
    "                while(cont == True and abs(datafiles['Time'][pos] - timestamp) < 7):\n",
    "                    for label in sequence:\n",
    "                        if (pd.isna(datafiles[label][pos]) == False): \n",
    "                            dflog.loc[idx, label] = datafiles[label][pos]\n",
    "                    pos += 1\n",
    "                    if (pos == len(datafiles)):\n",
    "                        cont = False\n",
    "\n",
    "        df_final = pd.DataFrame()\n",
    "        df_mid = pd.DataFrame()\n",
    "        df_mid_stop = pd.DataFrame()\n",
    "        dflog['Timestamp'] = dflog['Time']\n",
    "        df_final = dflog\n",
    "\n",
    "        df_final = pd.concat([df_final, pd.DataFrame({'Datetime' : [datetime.fromtimestamp(entry) for entry in df_final['Timestamp']]})], axis=1)\n",
    "        df_final.to_csv(str(DATASUMMARY / date2an / ('summary_'+date2an+'.txt')), sep='\\t', index=False)\n",
    "        \n",
    "    return df_final\n",
    "\n",
    "\n",
    "def loadShortSummary(date2an):  \n",
    "    '''\n",
    "    \n",
    "    make a document 'shortSum_date2an.txt' which only contains the rows of summary_date2an.txt which have a non NaN value somewhere in rcpc or pgunpc\n",
    "    \n",
    "    '''\n",
    "    if ((DATASUMMARY / date2an / ('shortSum_'+date2an+'.txt')).is_file() == True):# and (date2an < datetime.fromtimestamp((DATASUMMARY / date2an / ('shortSum_'+date2an+'.txt')).stat().st_mtime).strftime('%y_%m_%d')):\n",
    "        print('SHORT SUMMARY file for '+date2an+' already exists.')\n",
    "        return pd.read_csv(str(DATASUMMARY / date2an / ('shortSum_'+date2an+'.txt')), sep='\\t', index_col = [0])\n",
    "    else: \n",
    "        longData = loadDatafile(date2an)\n",
    "        elena = loadElena(date2an)\n",
    "        log = loadLog(date2an)\n",
    "\n",
    "        #drop all rows that have only nan for the pgunpc and rcpc (the threshold len(sequence_logFile) + len(elena_sequence) + 3 should be correct, not 100% sure)\n",
    "        shortData = longData.dropna(thresh=len(sequence_logFile) + len(elena_sequence) + 3)\n",
    "        shortData = shortData.drop(columns = ['Timestamp'])\n",
    "        shortData.to_csv(str(DATASUMMARY / date2an / ('shortSum_'+date2an+'.txt')), sep='\\t')\n",
    "\n",
    "    return shortData\n",
    "\n",
    "\n",
    "def add_date(date2an):\n",
    "    '''\n",
    "    \n",
    "    add the short summary from date2an to datafile23.txt\n",
    "    if no datafile23.txt exists, we create a new one\n",
    "    \n",
    "    '''\n",
    "    newfile = False #track we we created a new datafile23\n",
    "    \n",
    "    #if datafile23.txt does not exist, create a new one\n",
    "    if (DATAFILE / 'datafile23.txt').is_file() == False:\n",
    "        newfile = True\n",
    "        datafile = pd.DataFrame([['temp'] + [0]*124], columns = ['Date', 'Time', 'Datetime'] + sequence + sequence_logFile[1:] + elena_sequence)\n",
    "        datafile = datafile.set_index(['Date', list(datafile.index)]) #we have to have the datafile in the same shape as the summary we want to add\n",
    "        datafile = datafile.rename_axis(['Date', 'logFile pos']) #the second row of indices (level 1) are the position of the measurement in logFile for Date\n",
    "\n",
    "    else:\n",
    "        datafile = pd.read_csv(str(DATAFILE) + '/datafile23.txt', delimiter = '\\t', index_col = [0,1]) #get the datafile\n",
    "\n",
    "    #check that date2an isnt already in the file\n",
    "    for i in datafile.index.levels[0]:\n",
    "        if i == date2an:\n",
    "            return print('This date has already been added to the datafile.')\n",
    "        \n",
    "    summary = loadShortSummary(date2an) #load the summary for date2an, which we want to add to the file \n",
    "    summary.insert(0, 'Date', [date2an] * len(summary))\n",
    "    summary = summary.set_index(['Date', list(summary.index)]) #set date2an as the index in level 0 (the numbers are now at index level 1)\n",
    "    \n",
    "    datafile = pd.concat([datafile, summary]).sort_values(by = ['Date', 'logFile pos'], axis = 0) #add the summary to the datafile and sort by the date\n",
    "    \n",
    "    if (newfile == True):\n",
    "        datafile = datafile.drop('temp', axis = 0, level = 0)\n",
    "        \n",
    "    datafile.to_csv(str(DATAFILE) + '/datafile23.txt', sep='\\t')\n",
    "    \n",
    "    return \n",
    "\n",
    "\n",
    "def remove_date(date2an):\n",
    "    '''\n",
    "    \n",
    "    remove the data from date2an from the datafile23.txt\n",
    "    \n",
    "    '''\n",
    "    #if datafile23.txt does not exist, we just stop\n",
    "    if (DATAFILE / 'datafile23.txt').is_file() == False:\n",
    "        return print('This datafile does not exist yet.')\n",
    "    \n",
    "    #get the datafile\n",
    "    datafile = pd.read_csv(str(DATAFILE) + '/datafile23.txt', delimiter = '\\t', index_col = [0,1])\n",
    "    \n",
    "    #check if the date is in the datafile\n",
    "    date_exists = False \n",
    "    for i in datafile.index.levels[0]:\n",
    "        if i == date2an:\n",
    "            date_exists = True\n",
    "            break\n",
    "    \n",
    "    #if the date is not in the datafile, we can stop\n",
    "    if (date_exists == False):\n",
    "        return print('The date ' + date2an + ' is not in the datafile.')\n",
    "    \n",
    "    #remove the date from the datafiles\n",
    "    datafile = datafile.drop(date2an, axis = 0, level = 0)\n",
    "    \n",
    "    datafile.to_csv(str(DATAFILE) + '/datafile23.txt', sep='\\t') #save the datafile with the removed date\n",
    "    \n",
    "    return print('The date ' + date2an + ' has been removed from the datafile.')\n",
    "\n",
    "\n",
    "def read_datafile(day = False, log_pos = False, a = False):\n",
    "    '''\n",
    "    \n",
    "    Get a DataFrame as return, as specified from the inputs. If there are no inputs, the data gets returned with the indices the row number.\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    day = True the dataframe will have a multiindex where the data for each day is grouped toghether with the index in level 0 and level 1 is the row number \n",
    "    log_pos = True the dataframe will not have the row number as indices, but the position of the row measurement in the logFile for the day the data was taken\n",
    "    a = read the whole datafile\n",
    "    \n",
    "    '''\n",
    "    #get the data\n",
    "    datafile = pd.read_csv(str(DATAFILE) + '/datafile23.txt', delimiter = '\\t', index_col = [0,1])\n",
    "    \n",
    "    if (day == True):\n",
    "        if (log_pos == False):\n",
    "            datafile = datafile.reset_index(level = 1, drop = True)\n",
    "            datafile = datafile.set_index(pd.Series(range(len(datafile))), append = True)\n",
    "        return datafile\n",
    "        \n",
    "    if (log_pos == True):\n",
    "        datafile = datafile.reset_index(level = 0, drop = True)\n",
    "        return datafile\n",
    "    \n",
    "    if (a == True):\n",
    "        return pd.read_csv(str(DATAFILE) + '/datafile23.txt', delimiter = '\\t')\n",
    "        \n",
    "    return pd.read_csv(str(DATAFILE) + '/datafile23.txt', delimiter = '\\t', usecols = [val + 2 for val in range(124)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728cc282",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
